{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datetime import date, datetime\n",
    "from lib.predict import (\n",
    "    generate_sequences, SequenceDataset, LSTMForecaster, LSTM, \n",
    "    make_predictions_from_dataloader\n",
    ")\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import math\n",
    "# this ensures that the current MacOS version is at least 12.3+\n",
    "print(torch.backends.mps.is_available())\n",
    "# this ensures that the current current PyTorch installation was built with MPS activated.\n",
    "print(torch.backends.mps.is_built())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:36.217330Z",
     "iopub.status.busy": "2023-06-21T06:08:36.216529Z",
     "iopub.status.idle": "2023-06-21T06:08:36.234799Z",
     "shell.execute_reply": "2023-06-21T06:08:36.233873Z",
     "shell.execute_reply.started": "2023-06-21T06:08:36.217246Z"
    }
   },
   "outputs": [],
   "source": [
    "spydata = pd.read_csv(\"spydata.csv\")\n",
    "oil = spydata[[\"Date\", \"Close\", \"Volume\"]]\n",
    "# oil.loc[:,\"Date\"] = pd.to_datetime(oil.Date)\n",
    "oil = oil.set_index('Date').interpolate()\n",
    "# print(oil.isna().sum())\n",
    "df = oil.copy().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:37.164760Z",
     "iopub.status.busy": "2023-06-21T06:08:37.164368Z",
     "iopub.status.idle": "2023-06-21T06:08:37.176935Z",
     "shell.execute_reply": "2023-06-21T06:08:37.176206Z",
     "shell.execute_reply.started": "2023-06-21T06:08:37.164726Z"
    }
   },
   "outputs": [],
   "source": [
    "scalers = {}\n",
    "for x in df.columns:\n",
    "  scalers[x] = StandardScaler().fit(df[x].values.reshape(-1, 1))\n",
    "\n",
    "norm_df = df.copy()\n",
    "for i, key in enumerate(scalers.keys()):\n",
    "  norm = scalers[key].transform(norm_df.iloc[:, i].values.reshape(-1, 1))\n",
    "  norm_df.iloc[:, i] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:37.446676Z",
     "iopub.status.busy": "2023-06-21T06:08:37.446048Z",
     "iopub.status.idle": "2023-06-21T06:08:39.577541Z",
     "shell.execute_reply": "2023-06-21T06:08:39.576703Z",
     "shell.execute_reply.started": "2023-06-21T06:08:37.446623Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "nhid = 5\n",
    "sequence_len = 180\n",
    "n_dnn_layers = 5\n",
    "ninp = 2\n",
    "nout = 2\n",
    "split = 0.8\n",
    "n_epochs = 40\n",
    "\n",
    "sequences = generate_sequences(norm_df[[\"Close\", \"Volume\"]], sequence_len, nout, [\"Close\", \"Volume\"])\n",
    "dataset = SequenceDataset(sequences)\n",
    "\n",
    "train_len = int(len(dataset)*split)\n",
    "lens = [train_len, len(dataset)-train_len]\n",
    "train_ds, test_ds = random_split(dataset, lens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:39.578966Z",
     "iopub.status.busy": "2023-06-21T06:08:39.578730Z",
     "iopub.status.idle": "2023-06-21T06:08:39.582957Z",
     "shell.execute_reply": "2023-06-21T06:08:39.582249Z",
     "shell.execute_reply.started": "2023-06-21T06:08:39.578946Z"
    }
   },
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:39.584933Z",
     "iopub.status.busy": "2023-06-21T06:08:39.584668Z",
     "iopub.status.idle": "2023-06-21T06:08:39.590640Z",
     "shell.execute_reply": "2023-06-21T06:08:39.589647Z",
     "shell.execute_reply.started": "2023-06-21T06:08:39.584909Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_losses(tr, va):\n",
    "  import matplotlib.pyplot as plt\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(tr, label='train')\n",
    "  ax.plot(va, label='validation')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:39.592756Z",
     "iopub.status.busy": "2023-06-21T06:08:39.592431Z",
     "iopub.status.idle": "2023-06-21T06:08:39.605413Z",
     "shell.execute_reply": "2023-06-21T06:08:39.604759Z",
     "shell.execute_reply.started": "2023-06-21T06:08:39.592731Z"
    }
   },
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "\n",
    "  def __init__(self, n_features, n_hidden, n_outputs, sequence_len, n_lstm_layers=1, n_deep_layers=10, use_cuda=False, dropout=0.2):\n",
    "    '''\n",
    "    n_features: number of input features (1 for univariate forecasting)\n",
    "    n_hidden: number of neurons in each hidden layer\n",
    "    n_outputs: number of outputs to predict for each training example\n",
    "    n_deep_layers: number of hidden dense layers after the lstm layer\n",
    "    sequence_len: number of steps to look back at for prediction\n",
    "    dropout: float (0 < dropout < 1) dropout ratio between dense layers\n",
    "    '''\n",
    "    super().__init__()\n",
    "\n",
    "    self.n_lstm_layers = n_lstm_layers\n",
    "    self.nhid = n_hidden\n",
    "    self.use_cuda = use_cuda # set option for device selection\n",
    "\n",
    "    # LSTM Layer\n",
    "    self.lstm = nn.LSTM(n_features,\n",
    "                        n_hidden,\n",
    "                        num_layers=n_lstm_layers,\n",
    "                        batch_first=True) # As we have transformed our data in this way\n",
    "    \n",
    "    # first dense after lstm\n",
    "    self.fc1 = nn.Linear(n_hidden * sequence_len, n_hidden) \n",
    "    # Dropout layer \n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    # Create fully connected layers (n_hidden x n_deep_layers)\n",
    "    dnn_layers = []\n",
    "    for i in range(n_deep_layers):\n",
    "      # Last layer (n_hidden x n_outputs)\n",
    "      if i == n_deep_layers - 1:\n",
    "        dnn_layers.append(nn.ReLU())\n",
    "        dnn_layers.append(nn.Linear(self.nhid, n_outputs))\n",
    "      # All other layers (n_hidden x n_hidden) with dropout option\n",
    "      else:\n",
    "        dnn_layers.append(nn.ReLU())\n",
    "        dnn_layers.append(nn.Linear(self.nhid, self.nhid))\n",
    "        if dropout:\n",
    "          dnn_layers.append(nn.Dropout(p=dropout))\n",
    "    # compile DNN layers\n",
    "    self.dnn = nn.Sequential(*dnn_layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Initialize hidden state\n",
    "    hidden_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "    cell_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "\n",
    "    # move hidden state to device\n",
    "    if self.use_cuda:\n",
    "      hidden_state = hidden_state.to(device)\n",
    "      cell_state = cell_state.to(device)\n",
    "        \n",
    "    self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "    # Forward Pass\n",
    "    x, h = self.lstm(x, self.hidden) # LSTM\n",
    "    x = self.dropout(x.contiguous().view(x.shape[0], -1)) # Flatten lstm out \n",
    "    x = self.fc1(x) # First Dense\n",
    "    return self.dnn(x) # Pass forward through fully connected DNN.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:39.606570Z",
     "iopub.status.busy": "2023-06-21T06:08:39.606313Z",
     "iopub.status.idle": "2023-06-21T06:08:39.615618Z",
     "shell.execute_reply": "2023-06-21T06:08:39.614892Z",
     "shell.execute_reply.started": "2023-06-21T06:08:39.606544Z"
    }
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = 'cuda' if USE_CUDA else 'cpu'\n",
    "lr = 0.01\n",
    "model =  LSTMForecaster(\n",
    "            n_features=ninp, \n",
    "            n_hidden=nhid, \n",
    "            n_outputs=nout, \n",
    "            sequence_len=sequence_len, \n",
    "            n_lstm_layers=1,\n",
    "            n_deep_layers=n_dnn_layers, \n",
    "            use_cuda=USE_CUDA,\n",
    "            dropout=0.2\n",
    "        ).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-06-21T06:08:39.617031Z",
     "iopub.status.busy": "2023-06-21T06:08:39.616747Z",
     "iopub.status.idle": "2023-06-21T06:08:39.924259Z",
     "shell.execute_reply": "2023-06-21T06:08:39.921936Z",
     "shell.execute_reply.started": "2023-06-21T06:08:39.617005Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========^^^^^^^^\n",
      "x-shape = torch.Size([16, 180, 2]), y-shape = torch.Size([16, 2, 2]), preds-shape = torch.Size([16, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/meetri/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([16, 2, 2])) that is different to the input size (torch.Size([16, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (16) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3e7cb8bce71d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"x-shape = {x.shape}, y-shape = {y.shape}, preds-shape = {preds.shape}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"******\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 536\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   3292\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3294\u001b[0;31m     \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3295\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/torch/functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[0;34m(*tensors)\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (16) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "t_losses, v_losses = [], []\n",
    "for epoch in range(n_epochs):\n",
    "  train_loss, valid_loss = 0.0, 0.0\n",
    "\n",
    "\n",
    "  # train step\n",
    "  model.train()\n",
    "  for x, y in trainloader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    y = y.squeeze().to(device)   \n",
    "\n",
    "    # print(len(x))\n",
    "    # print(len(y))\n",
    "    \n",
    "    # (2in,1out) x-shape = torch.Size([20, 180, 2]), y-shape = torch.Size([20])\n",
    "    # (2in,2out) x-shape = torch.Size([16, 180, 2]), y-shape = torch.Size([16, 2, 2]), preds-shape = torch.Size([16, 2])\n",
    "    # Forward Pass\n",
    "    preds = model(x).squeeze()    \n",
    "    print(f\"==========^^^^^^^^\")\n",
    "    print(f\"x-shape = {x.shape}, y-shape = {y.shape}, preds-shape = {preds.shape}\")\n",
    "\n",
    "    loss = criterion(preds, y)\n",
    "    print(f\"******\")\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  epoch_loss = train_loss / len(trainloader)\n",
    "  t_losses.append(epoch_loss)\n",
    "  \n",
    "  # validation step\n",
    "  model.eval()\n",
    "  for x, y in testloader:\n",
    "    with torch.no_grad():\n",
    "      x, y = x.to(device), y.squeeze().to(device)\n",
    "      preds = model(x).squeeze()\n",
    "      error = criterion(preds, y)\n",
    "    valid_loss += error.item()\n",
    "  valid_loss = valid_loss / len(testloader)\n",
    "  v_losses.append(valid_loss)\n",
    "      \n",
    "  print(f'{epoch} - train: {epoch_loss}, valid: {valid_loss}')\n",
    "\n",
    "plot_losses(t_losses, v_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T06:08:39.925634Z",
     "iopub.status.idle": "2023-06-21T06:08:39.927958Z"
    }
   },
   "outputs": [],
   "source": [
    "class Forecaster:\n",
    "\n",
    "  def __init__(self, model, data, target, tw):\n",
    "    self.model = model\n",
    "    self.data = data\n",
    "    self.tw = tw\n",
    "    self.target = target\n",
    "\n",
    "  def plot_forecast(self, history):\n",
    "    fig = go.Figure()\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=history.index, y=history.actual,\n",
    "                        mode='lines',\n",
    "                        name='actual'))\n",
    "    fig.add_trace(go.Scatter(x=history.index, y=history.forecast,\n",
    "                        mode='lines',\n",
    "                        name='forecast'))\n",
    "    fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=2400,\n",
    "    height=800,)\n",
    "    fig.show()\n",
    "  \n",
    "  def one_step_forecast(self, history):\n",
    "      '''\n",
    "      history: a sequence of values representing the latest values of the time \n",
    "      series, requirement -> len(history.shape) == 2\n",
    "\n",
    "      outputs a single value which is the prediction of the next value in the\n",
    "      sequence.\n",
    "      '''\n",
    "      self.model.cpu()\n",
    "      self.model.eval()\n",
    "      with torch.no_grad():\n",
    "        pre = torch.Tensor(history).unsqueeze(0)\n",
    "        pred = self.model(pre)\n",
    "      return pred.detach().numpy().reshape(-1)\n",
    "\n",
    "  def n_step_forecast(self, n: int, forecast_from: int=None, plot=False):\n",
    "      '''\n",
    "      n: integer defining how many steps to forecast\n",
    "      forecast_from: integer defining which index to forecast from. None if\n",
    "      you want to forecast from the end.\n",
    "      plot: True if you want to output a plot of the forecast, False if not.\n",
    "      '''\n",
    "      history = self.data[self.target] # .to_frame()\n",
    "    \n",
    "      # print(history)\n",
    "      # Create initial sequence input based on where in the series to forecast \n",
    "      # from.\n",
    "      if forecast_from:\n",
    "        pre = list(history[forecast_from - self.tw : forecast_from][self.target].values)\n",
    "      else:\n",
    "        pre = history[self.target].values[-self.tw:].tolist()\n",
    "        \n",
    "      # Call one_step_forecast n times and append prediction to history\n",
    "      for i, step in enumerate(range(n)):\n",
    "        pre_ = np.array(pre[-self.tw:])  # .reshape(-1, 1)\n",
    "        forecast = self.one_step_forecast(pre_).squeeze()\n",
    "        # pre.append(forecast)\n",
    "\n",
    "      res = history.copy()\n",
    "      ls = [np.nan for i in range(len(history))]\n",
    "\n",
    "      # Note: I have not handled the edge case where the start index + n crosses\n",
    "      # the end of the dataset\n",
    "      if forecast_from:\n",
    "        ls[forecast_from : forecast_from + n] = list(np.array(pre[-n:]))\n",
    "        res['forecast'] = ls\n",
    "        res.columns = ['actual', 'forecast']\n",
    "      else:\n",
    "        fc = ls + list(np.array(pre[-n:]))\n",
    "        ls = ls + [np.nan for i in range(len(pre[-n:]))]\n",
    "        ls[:len(history)] = history[self.target].values\n",
    "        res = pd.DataFrame([ls, fc], index=['actual', 'forecast']).T\n",
    "\n",
    "      if plot:\n",
    "        self.plot_forecast(res)\n",
    "      return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T06:08:39.930436Z",
     "iopub.status.idle": "2023-06-21T06:08:39.931066Z"
    }
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "fc = Forecaster(model, norm_df, [\"Close\", \"Volume\"], 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T06:08:39.932429Z",
     "iopub.status.idle": "2023-06-21T06:08:39.932932Z"
    }
   },
   "outputs": [],
   "source": [
    "history = fc.n_step_forecast(200, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-06-21T06:08:39.934009Z",
     "iopub.status.idle": "2023-06-21T06:08:39.934606Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = history[[\"forecast\"]].dropna()\n",
    "a = history[[\"actual\"]].dropna()\n",
    "\n",
    "x = list(zip(*a[\"actual\"].values))\n",
    "x2 = list(zip(*f[\"forecast\"].values))\n",
    "xb = pd.DataFrame(np.empty_like(a.actual))\n",
    "\n",
    "# xb.loc(len(x2[0]), \"forcast\") = x2\n",
    "xb.iloc[-180:, 0] = x2[0]\n",
    "\n",
    "plt.plot(x[0]), plt.plot(xb[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
