{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0npuw4zPLvyM"
   },
   "source": [
    "# Time Series Forecasting Using A Long Short-Term Memory Neural Network\n",
    "\n",
    "Welcome to the Univariate Timeseries Forecasting Tutorial! This notebook contains the implementation of a Long Short-Term Memory neural network to forecast a target time series column.\n",
    "\n",
    "`tw` : training window\n",
    "\n",
    "`pw` : prediction window (horizon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwaEwrbPLs_U"
   },
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qostfKiUNfZn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from datetime import date, datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20174,
     "status": "ok",
     "timestamp": 1673929193031,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "yOlo6QfTPdm4",
    "outputId": "48ddd45a-0e23-4485-884a-984665f6aabe"
   },
   "outputs": [],
   "source": [
    "# Load from CSV, Colab Code\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "edscnrg0qll8"
   },
   "source": [
    "## Data Preparation\n",
    "\n",
    "\n",
    "The dataset well be using was used in a competition for timeseries forecasting, which can be found [here](https://www.kaggle.com/competitions/store-sales-time-series-forecasting/data?select=transactions.csv).\n",
    "\n",
    "The dataset consists of 4 tables:\n",
    "\n",
    "\n",
    "*   Transactions\n",
    "*   Holidays/Events\n",
    "*   Price of Oil\n",
    "*   Sales\n",
    "\n",
    "So, let's load up the oil table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-1GH28AqlBl"
   },
   "outputs": [],
   "source": [
    "# Path to where you have saved the datasets\n",
    "# drive_path = \"drive/MyDrive/Colab Notebooks/Medium/data/\"\n",
    "# oil = pd.read_csv(os.path.join(drive_path, 'timeseries/oil.csv'))\n",
    "spydata = pd.read_csv(\"spydata.csv\")\n",
    "oil = spydata[[\"Date\", \"Close\", \"Volume\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673931478958,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "DlXyCbaVsMP1",
    "outputId": "0f1c6649-ff82-47fa-e2b3-1e487d33e1d0"
   },
   "outputs": [],
   "source": [
    "oil.Date = pd.to_datetime(oil.Date)\n",
    "oil = oil.set_index('Date').interpolate()\n",
    "print(oil.isna().sum())\n",
    "df = oil.copy().dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oil.plot(y=[\"Close\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uob5LrrLbBJT"
   },
   "outputs": [],
   "source": [
    "def generate_sequences(df: pd.DataFrame, tw: int, pw: int, target_columns, inplace=False, drop_targets=False):\n",
    "  '''\n",
    "  df: Pandas DataFrame of the univariate time-series\n",
    "  tw: Training Window - Integer defining how many steps to look back\n",
    "  pw: Prediction Window - Integer defining how many steps to predict\n",
    "\n",
    "  returns: dictionary of sequences and targets for all sequences\n",
    "  '''\n",
    "  data = dict() # Store results into a dictionary\n",
    "  L = len(df)\n",
    "  for i in range(L-tw):\n",
    "    # Option to drop target from dataframe\n",
    "    if drop_targets:\n",
    "      df.drop(target_columns, axis=1, inplace=True)\n",
    "\n",
    "    # Get current sequence  \n",
    "    sequence = df[i:i+tw].values\n",
    "    # Get values right after the current sequence\n",
    "    target = df[i+tw:i+tw+pw][target_columns].values\n",
    "    data[i] = {'sequence': sequence, 'target': target}\n",
    "  return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZ5BgNd-fu9E"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalers = {}\n",
    "for x in df.columns:\n",
    "  scalers[x] = StandardScaler().fit(df[x].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mz88qi2Vgn5-"
   },
   "outputs": [],
   "source": [
    "norm_df = df.copy()\n",
    "for i, key in enumerate(scalers.keys()):\n",
    "  norm = scalers[key].transform(norm_df.iloc[:, i].values.reshape(-1, 1))\n",
    "  norm_df.iloc[:, i] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V-QmVpiHa1MN"
   },
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "\n",
    "  def __init__(self, df):\n",
    "    self.data = df\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    sample = self.data[idx]\n",
    "    return torch.Tensor(sample['sequence']), torch.Tensor(sample['target'])\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0qGGjN0YbYgU"
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "nhid = 50\n",
    "nout = 1\n",
    "sequence_len = 180\n",
    "n_dnn_layers = 5\n",
    "ninp = 2\n",
    "split = 0.8\n",
    "\n",
    "sequences = generate_sequences(norm_df[[\"Close\", \"Volume\"]], sequence_len, nout, [\"Close\"])\n",
    "dataset = SequenceDataset(sequences)\n",
    "\n",
    "train_len = int(len(dataset)*split)\n",
    "lens = [train_len, len(dataset)-train_len]\n",
    "train_ds, test_ds = random_split(dataset, lens)\n",
    "trainloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)\n",
    "testloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1673931503721,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "9oxVK3aUEtcz",
    "outputId": "3a70fae1-ca5b-4b72-c6fe-e4ed6373caaa"
   },
   "outputs": [],
   "source": [
    "x, y = next(iter(trainloader))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rOKN4LbLBvq"
   },
   "source": [
    "### PyTorch Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aVfqLswYacDa"
   },
   "outputs": [],
   "source": [
    "class LSTMForecaster(nn.Module):\n",
    "\n",
    "\n",
    "  def __init__(self, n_features, n_hidden, n_outputs, sequence_len, n_lstm_layers=1, n_deep_layers=10, use_cuda=False, dropout=0.2):\n",
    "    '''\n",
    "    n_features: number of input features (1 for univariate forecasting)\n",
    "    n_hidden: number of neurons in each hidden layer\n",
    "    n_outputs: number of outputs to predict for each training example\n",
    "    n_deep_layers: number of hidden dense layers after the lstm layer\n",
    "    sequence_len: number of steps to look back at for prediction\n",
    "    dropout: float (0 < dropout < 1) dropout ratio between dense layers\n",
    "    '''\n",
    "    super().__init__()\n",
    "\n",
    "    self.n_lstm_layers = n_lstm_layers\n",
    "    self.nhid = n_hidden\n",
    "    self.use_cuda = use_cuda # set option for device selection\n",
    "\n",
    "    # LSTM Layer\n",
    "    self.lstm = nn.LSTM(n_features,\n",
    "                        n_hidden,\n",
    "                        num_layers=n_lstm_layers,\n",
    "                        batch_first=True) # As we have transformed our data in this way\n",
    "    \n",
    "    # first dense after lstm\n",
    "    self.fc1 = nn.Linear(n_hidden * sequence_len, n_hidden) \n",
    "    # Dropout layer \n",
    "    self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    # Create fully connected layers (n_hidden x n_deep_layers)\n",
    "    dnn_layers = []\n",
    "    for i in range(n_deep_layers):\n",
    "      # Last layer (n_hidden x n_outputs)\n",
    "      if i == n_deep_layers - 1:\n",
    "        dnn_layers.append(nn.ReLU())\n",
    "        dnn_layers.append(nn.Linear(nhid, n_outputs))\n",
    "      # All other layers (n_hidden x n_hidden) with dropout option\n",
    "      else:\n",
    "        dnn_layers.append(nn.ReLU())\n",
    "        dnn_layers.append(nn.Linear(nhid, nhid))\n",
    "        if dropout:\n",
    "          dnn_layers.append(nn.Dropout(p=dropout))\n",
    "    # compile DNN layers\n",
    "    self.dnn = nn.Sequential(*dnn_layers)\n",
    "\n",
    "  def forward(self, x):\n",
    "\n",
    "    # Initialize hidden state\n",
    "    hidden_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "    cell_state = torch.zeros(self.n_lstm_layers, x.shape[0], self.nhid)\n",
    "\n",
    "    # move hidden state to device\n",
    "    if self.use_cuda:\n",
    "      hidden_state = hidden_state.to(device)\n",
    "      cell_state = cell_state.to(device)\n",
    "        \n",
    "    self.hidden = (hidden_state, cell_state)\n",
    "\n",
    "    # Forward Pass\n",
    "    x, h = self.lstm(x, self.hidden) # LSTM\n",
    "    x = self.dropout(x.contiguous().view(x.shape[0], -1)) # Flatten lstm out \n",
    "    x = self.fc1(x) # First Dense\n",
    "    return self.dnn(x) # Pass forward through fully connected DNN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m6IZxxr5LE9F"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oeYtNPYBxdVn"
   },
   "outputs": [],
   "source": [
    "def plot_losses(tr, va):\n",
    "  import matplotlib.pyplot as plt\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.plot(tr, label='train')\n",
    "  ax.plot(va, label='validation')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A85FEsORr41v"
   },
   "outputs": [],
   "source": [
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = 'cuda' if USE_CUDA else 'cpu'\n",
    "lr = 0.01\n",
    "n_epochs = 200\n",
    "\n",
    "model = LSTMForecaster(ninp, nhid, nout, sequence_len, n_deep_layers=n_dnn_layers, use_cuda=USE_CUDA).to(device)\n",
    "criterion = nn.MSELoss().to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 622
    },
    "executionInfo": {
     "elapsed": 68871,
     "status": "ok",
     "timestamp": 1673931624668,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "Go9CC6Q-swxl",
    "outputId": "4b93a86e-2dea-49bb-e69b-f75fb716c006"
   },
   "outputs": [],
   "source": [
    "t_losses, v_losses = [], []\n",
    "for epoch in range(n_epochs):\n",
    "  train_loss, valid_loss = 0.0, 0.0\n",
    "\n",
    "\n",
    "  # train step\n",
    "  model.train()\n",
    "  for x, y in trainloader:\n",
    "    optimizer.zero_grad()\n",
    "    x = x.to(device)\n",
    "    y  = y.squeeze().to(device)    \n",
    "    # print(f\"x-shape = {x.shape}, y-shape = {y.shape}\")\n",
    "    # (2in,1out) x-shape = torch.Size([20, 180, 2]), y-shape = torch.Size([20])\n",
    "    # Forward Pass\n",
    "    preds = model(x).squeeze()    \n",
    "    loss = criterion(preds, y)\n",
    "    train_loss += loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  epoch_loss = train_loss / len(trainloader)\n",
    "  t_losses.append(epoch_loss)\n",
    "  \n",
    "  # validation step\n",
    "  model.eval()\n",
    "  for x, y in testloader:\n",
    "    with torch.no_grad():\n",
    "      x, y = x.to(device), y.squeeze().to(device)\n",
    "      preds = model(x).squeeze()\n",
    "      error = criterion(preds, y)\n",
    "    valid_loss += error.item()\n",
    "  valid_loss = valid_loss / len(testloader)\n",
    "  v_losses.append(valid_loss)\n",
    "      \n",
    "  print(f'{epoch} - train: {epoch_loss}, valid: {valid_loss}')\n",
    "\n",
    "plot_losses(t_losses, v_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ZLnmaaMJ3ip"
   },
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "525S3EaN6Ta4"
   },
   "outputs": [],
   "source": [
    "def make_predictions_from_dataloader(model, dataloader):\n",
    "  model.eval()\n",
    "  predictions, actuals = [], []\n",
    "  for x, y in unshuffled_dataloader:\n",
    "    with torch.no_grad():\n",
    "      p = model(x)\n",
    "      predictions.append(p)\n",
    "      actuals.append(y.squeeze())\n",
    "  predictions = torch.cat(predictions).numpy()\n",
    "  actuals = torch.cat(actuals).numpy()\n",
    "  return predictions.squeeze(), actuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1673931673016,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "2MWTm_p79Smf",
    "outputId": "5d505f61-a792-4d2e-c937-94fd308515f0"
   },
   "outputs": [],
   "source": [
    "unshuffled_dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=False, drop_last=True)\n",
    "P, Y = make_predictions_from_dataloader(model, unshuffled_dataloader)\n",
    "P.shape, Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 602,
     "status": "ok",
     "timestamp": 1673931674785,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "fKa6dO5b7Fxz",
    "outputId": "c55f53ee-0d7a-4202-98c7-98aa4690f0fc"
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "pdf = pd.DataFrame([P, Y], index=['predictions', 'actuals']).T\n",
    "\n",
    "fig = px.line(pdf)\n",
    "fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=2400,\n",
    "    height=800,)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf[-300:].plot(y=[\"predictions\", \"actuals\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c0AFCGuZD5JW"
   },
   "source": [
    "## Forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6HogQtoJ4zAo"
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "\n",
    "class Forecaster:\n",
    "\n",
    "  def __init__(self, model, data, target, tw):\n",
    "    self.model = model\n",
    "    self.data = data\n",
    "    self.tw = tw\n",
    "    self.target = target\n",
    "\n",
    "  def plot_forecast(self, history):\n",
    "    fig = go.Figure()\n",
    "    # Add traces\n",
    "    fig.add_trace(go.Scatter(x=history.index, y=history.actual,\n",
    "                        mode='lines',\n",
    "                        name='actual'))\n",
    "    fig.add_trace(go.Scatter(x=history.index, y=history.forecast,\n",
    "                        mode='lines',\n",
    "                        name='forecast'))\n",
    "    fig.update_layout(\n",
    "    autosize=False,\n",
    "    width=2400,\n",
    "    height=800,)\n",
    "    fig.show()\n",
    "  \n",
    "  def one_step_forecast(self, history):\n",
    "      '''\n",
    "      history: a sequence of values representing the latest values of the time \n",
    "      series, requirement -> len(history.shape) == 2\n",
    "\n",
    "      outputs a single value which is the prediction of the next value in the\n",
    "      sequence.\n",
    "      '''\n",
    "      self.model.cpu()\n",
    "      self.model.eval()\n",
    "      with torch.no_grad():\n",
    "        pre = torch.Tensor(history).unsqueeze(0)\n",
    "        pred = self.model(pre)\n",
    "      return pred.detach().numpy().reshape(-1)\n",
    "\n",
    "  def n_step_forecast(self, n: int, forecast_from: int=None, plot=False):\n",
    "      '''\n",
    "      n: integer defining how many steps to forecast\n",
    "      forecast_from: integer defining which index to forecast from. None if\n",
    "      you want to forecast from the end.\n",
    "      plot: True if you want to output a plot of the forecast, False if not.\n",
    "      '''\n",
    "      history = self.data[self.target] # .to_frame()\n",
    "    \n",
    "      # print(history)\n",
    "      # Create initial sequence input based on where in the series to forecast \n",
    "      # from.\n",
    "      if forecast_from:\n",
    "        pre = list(history[forecast_from - self.tw : forecast_from][self.target].values)\n",
    "      else:\n",
    "        pre = list(history[self.target].values[-self.tw:])\n",
    "        \n",
    "      # Call one_step_forecast n times and append prediction to history\n",
    "      for i, step in enumerate(range(n)):\n",
    "        pre_ = np.array(pre[-self.tw:]) # .reshape(-1, 1)\n",
    "        print(pre_)\n",
    "        break\n",
    "        forecast = self.one_step_forecast(pre_).squeeze()\n",
    "        pre.append(forecast)\n",
    "\n",
    "      res = history.copy()\n",
    "      ls = [np.nan for i in range(len(history))]\n",
    "\n",
    "      # Note: I have not handled the edge case where the start index + n crosses\n",
    "      # the end of the dataset\n",
    "      if forecast_from:\n",
    "        ls[forecast_from : forecast_from + n] = list(np.array(pre[-n:]))\n",
    "        res['forecast'] = ls\n",
    "        res.columns = ['actual', 'forecast']\n",
    "      else:\n",
    "        fc = ls + list(np.array(pre[-n:]))\n",
    "        ls = ls + [np.nan for i in range(len(pre[-n:]))]\n",
    "        ls[:len(history)] = history[self.target].values\n",
    "        res = pd.DataFrame([ls, fc], index=['actual', 'forecast']).T\n",
    "\n",
    "      if plot:\n",
    "        self.plot_forecast(res)\n",
    "      return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgXQhCvi548X"
   },
   "outputs": [],
   "source": [
    "fc = Forecaster(model, norm_df, [\"Close\", \"Volume\"], 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = fc.data[[\"Close\", \"Volume\"]].values\n",
    "history[-fc.tw:][0]\n",
    "# pre = list(history[self.target].values)[-self.tw:]\n",
    "# history[[\"Close\", \"Volume\"]].values[-fc.tw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 817
    },
    "executionInfo": {
     "elapsed": 1335,
     "status": "ok",
     "timestamp": 1673933006844,
     "user": {
      "displayName": "Zain Baquar",
      "userId": "03633179948579372374"
     },
     "user_tz": 300
    },
    "id": "_zwhHwaU5-VL",
    "outputId": "0f3e339b-70b9-4ddd-df58-68c38dde4136"
   },
   "outputs": [],
   "source": [
    "history = fc.n_step_forecast(200, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = history[[\"forecast\"]].dropna()\n",
    "a = history[[\"actual\"]].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "f = history[[\"forecast\"]].dropna()\n",
    "a = history[[\"actual\"]].dropna()\n",
    "\n",
    "x = list(zip(*a[\"actual\"].values))\n",
    "x2 = list(zip(*f[\"forecast\"].values))\n",
    "xb = pd.DataFrame(np.empty_like(a.actual))\n",
    "\n",
    "# xb.loc(len(x2[0]), \"forcast\") = x2\n",
    "xb.iloc[-180:, 0] = x2[0]\n",
    "\n",
    "plt.plot(x[0]), plt.plot(xb[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x[0][-180:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(x[0][-180:]).plot()\n",
    "xb.fillna(0)[-180:].reset_index().plot(y=[0]), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
