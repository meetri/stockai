{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "748c056b-5e4d-42da-b421-73dc9eb12f4b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Stock Forecaster Test 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c50fc53-feb3-419e-b8b3-0df084ee05b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Libraries and Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e15b9ef-a9c2-43ee-aa77-11c27cf26009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/stallion.html\n",
    "# https://www.sciencedirect.com/science/article/pii/S2666827022000378\n",
    "# https://www.sciencedirect.com/science/article/pii/S2666827022000378\n",
    "from lib.forecast2 import StockForecast\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import copy\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "\n",
    "from lib.scraper import StockScraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "149a7e2e-1283-4b2c-a25f-e403f4df3133",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-29 17:53:20.856922\n",
      "1688086400.856922\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = datetime.now()\n",
    "print(n), print(n.timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdf51982-7966-491c-a2d8-a56a68a8bc0c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m st \u001b[38;5;241m=\u001b[39m math\u001b[38;5;241m.\u001b[39mfloor(n\u001b[38;5;241m.\u001b[39mtimestamp())\n\u001b[1;32m      3\u001b[0m en \u001b[38;5;241m=\u001b[39m st \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m24\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m----> 5\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mrange\u001b[39m(st \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m, en \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[1;32m      6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNewDate\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      7\u001b[0m df\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/frame.py:3980\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[1;32m   3978\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3979\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[0;32m-> 3980\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/frame.py:4174\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   4164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4165\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4166\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[1;32m   4167\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4172\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[1;32m   4173\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4174\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4176\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   4177\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m   4178\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   4179\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[1;32m   4180\u001b[0m     ):\n\u001b[1;32m   4181\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[1;32m   4182\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/frame.py:4905\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4892\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sanitize_column\u001b[39m(\u001b[38;5;28mself\u001b[39m, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ArrayLike:\n\u001b[1;32m   4893\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4894\u001b[0m \u001b[38;5;124;03m    Ensures new columns (which go into the BlockManager as new blocks) are\u001b[39;00m\n\u001b[1;32m   4895\u001b[0m \u001b[38;5;124;03m    always copied and converted into an array.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4903\u001b[0m \u001b[38;5;124;03m    numpy.ndarray or ExtensionArray\u001b[39;00m\n\u001b[1;32m   4904\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4905\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_valid_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4907\u001b[0m     \u001b[38;5;66;03m# We can get there through isetitem with a DataFrame\u001b[39;00m\n\u001b[1;32m   4908\u001b[0m     \u001b[38;5;66;03m# or through loc single_block_path\u001b[39;00m\n\u001b[1;32m   4909\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/frame.py:4243\u001b[0m, in \u001b[0;36mDataFrame._ensure_valid_index\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m   4241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[1;32m   4242\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 4243\u001b[0m         value \u001b[38;5;241m=\u001b[39m \u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4244\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m   4245\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   4246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a frame with no defined index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand a value that cannot be converted to a Series\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   4248\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    468\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    469\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 470\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43msanitize_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    472\u001b[0m     manager \u001b[38;5;241m=\u001b[39m get_option(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.data_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    473\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/construction.py:542\u001b[0m, in \u001b[0;36msanitize_array\u001b[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[1;32m    539\u001b[0m     data \u001b[38;5;241m=\u001b[39m lib\u001b[38;5;241m.\u001b[39mitem_from_zerodim(data)\n\u001b[1;32m    540\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mrange\u001b[39m):\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;66;03m# GH#16804\u001b[39;00m\n\u001b[0;32m--> 542\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43mrange_to_ndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pandas/core/construction.py:663\u001b[0m, in \u001b[0;36mrange_to_ndarray\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;66;03m# GH#30171 perf avoid realizing range as a list in np.array\u001b[39;00m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 663\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mint64\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOverflowError\u001b[39;00m:\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;66;03m# GH#30173 handling for ranges that overflow int64\u001b[39;00m\n\u001b[1;32m    666\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (rng\u001b[38;5;241m.\u001b[39mstart \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m rng\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (rng\u001b[38;5;241m.\u001b[39mstop \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m rng\u001b[38;5;241m.\u001b[39mstep \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "                \n",
    "df[\"Date\"] = pd.date_ran"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20e2fa66-f4d9-43bb-8c3d-c9476e326b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning.pytorch as pl\n",
    "from lightning.pytorch.callbacks import EarlyStopping, LearningRateMonitor\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from pytorch_forecasting import Baseline, TemporalFusionTransformer, TimeSeriesDataSet\n",
    "from pytorch_forecasting.data import GroupNormalizer\n",
    "from pytorch_forecasting.metrics import MAE, SMAPE, PoissonLoss, QuantileLoss\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af7f7c6b-6edf-4391-bc27-2fa875fdc16d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# https://fred.stlouisfed.org/series/UNRATE\n",
    "\n",
    "effr_data = pd.read_csv(f\"macroeconomics_data/EFFR.csv\")\n",
    "umcsent_data = pd.read_csv(f\"macroeconomics_data/UMCSENT.csv\")\n",
    "unrate_data = pd.read_csv(f\"macroeconomics_data/UNRATE.csv\")\n",
    "\n",
    "macro_data = effr_data.merge(umcsent_data, on=\"DATE\",how=\"left\" )\n",
    "macro_data = macro_data.merge(unrate_data, on=\"DATE\",how=\"left\" )\n",
    "macro_data[\"Date\"] = macro_data[\"DATE\"]\n",
    "macro_data = macro_data.drop(columns=[\"DATE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11ff55f0-eba1-4ac6-9188-1ff68608fa57",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5996, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EFFR</th>\n",
       "      <th>UMCSENT</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5991</th>\n",
       "      <td>5.07</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-06-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5992</th>\n",
       "      <td>5.07</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-06-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5993</th>\n",
       "      <td>5.07</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-06-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5994</th>\n",
       "      <td>5.07</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-06-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5995</th>\n",
       "      <td>5.07</td>\n",
       "      <td>62.0</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2023-06-26</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      EFFR  UMCSENT  UNRATE        Date\n",
       "5991  5.07     62.0     3.7  2023-06-20\n",
       "5992  5.07     62.0     3.7  2023-06-21\n",
       "5993  5.07     62.0     3.7  2023-06-22\n",
       "5994  5.07     62.0     3.7  2023-06-23\n",
       "5995  5.07     62.0     3.7  2023-06-26"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_data[\"EFFR\"] = macro_data[\"EFFR\"].replace(\".\",np.nan).fillna(method=\"bfill\")\n",
    "macro_data[\"UMCSENT\"] = macro_data[\"UMCSENT\"].fillna(method=\"ffill\")\n",
    "macro_data[\"UNRATE\"] = macro_data[\"UNRATE\"].fillna(method=\"ffill\")\n",
    "print(macro_data.shape)\n",
    "macro_data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "826dece2-776f-43ad-b944-2d68a5ed5e70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY shape = (2517, 4)\n",
      "VIX shape = (2517, 2)\n",
      "DIX shape = (3778, 2)\n",
      "MERGE shape = (2517, 6)\n",
      "macro shape = (5996, 4)\n",
      "MERGE shape = (2517, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>VIX</th>\n",
       "      <th>Dollar Index</th>\n",
       "      <th>EFFR</th>\n",
       "      <th>UMCSENT</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-06-26</td>\n",
       "      <td>4.14</td>\n",
       "      <td>19841200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.209999</td>\n",
       "      <td>82.949997</td>\n",
       "      <td>0.09</td>\n",
       "      <td>84.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-06-27</td>\n",
       "      <td>4.08</td>\n",
       "      <td>17426100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>82.910004</td>\n",
       "      <td>0.09</td>\n",
       "      <td>84.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>4.08</td>\n",
       "      <td>13329600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.860001</td>\n",
       "      <td>83.169998</td>\n",
       "      <td>0.07</td>\n",
       "      <td>84.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>2</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-07-01</td>\n",
       "      <td>4.10</td>\n",
       "      <td>10712200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.370001</td>\n",
       "      <td>82.980003</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>3</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-02</td>\n",
       "      <td>3.97</td>\n",
       "      <td>17766600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.440001</td>\n",
       "      <td>83.540001</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2013-07-03</td>\n",
       "      <td>4.06</td>\n",
       "      <td>11315900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.200001</td>\n",
       "      <td>83.230003</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>5</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2013-07-05</td>\n",
       "      <td>4.07</td>\n",
       "      <td>8965400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.890000</td>\n",
       "      <td>84.419998</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>6</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2013-07-08</td>\n",
       "      <td>4.00</td>\n",
       "      <td>16930900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.780000</td>\n",
       "      <td>84.199997</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>7</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2013-07-09</td>\n",
       "      <td>4.05</td>\n",
       "      <td>9550900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.350000</td>\n",
       "      <td>84.580002</td>\n",
       "      <td>0.10</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>8</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2013-07-10</td>\n",
       "      <td>3.98</td>\n",
       "      <td>19122800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.210000</td>\n",
       "      <td>84.040001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>9</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2013-07-11</td>\n",
       "      <td>4.45</td>\n",
       "      <td>106975700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.010000</td>\n",
       "      <td>82.750000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>10</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2013-07-12</td>\n",
       "      <td>4.32</td>\n",
       "      <td>50286600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.840000</td>\n",
       "      <td>82.989998</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>11</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2013-07-15</td>\n",
       "      <td>4.40</td>\n",
       "      <td>21953700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.790000</td>\n",
       "      <td>83.040001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>12</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2013-07-16</td>\n",
       "      <td>4.43</td>\n",
       "      <td>39716700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.420000</td>\n",
       "      <td>82.430000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>13</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2013-07-17</td>\n",
       "      <td>4.38</td>\n",
       "      <td>17002100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.780000</td>\n",
       "      <td>82.709999</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>14</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2013-07-18</td>\n",
       "      <td>4.64</td>\n",
       "      <td>70347000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.770000</td>\n",
       "      <td>82.820000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>15</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2013-07-19</td>\n",
       "      <td>4.03</td>\n",
       "      <td>151516000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.540000</td>\n",
       "      <td>82.580002</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>16</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>3.90</td>\n",
       "      <td>50010900</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.290000</td>\n",
       "      <td>82.220001</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>17</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2013-07-23</td>\n",
       "      <td>3.66</td>\n",
       "      <td>76847700</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.660000</td>\n",
       "      <td>82.010002</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>18</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2013-07-24</td>\n",
       "      <td>3.63</td>\n",
       "      <td>50913500</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.180000</td>\n",
       "      <td>82.300003</td>\n",
       "      <td>0.09</td>\n",
       "      <td>85.1</td>\n",
       "      <td>7.3</td>\n",
       "      <td>19</td>\n",
       "      <td>amd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Close     Volume  Stock Splits        VIX  Dollar Index  EFFR  \\\n",
       "0   2013-06-26   4.14   19841200           0.0  17.209999     82.949997  0.09   \n",
       "1   2013-06-27   4.08   17426100           0.0  16.860001     82.910004  0.09   \n",
       "2   2013-06-28   4.08   13329600           0.0  16.860001     83.169998  0.07   \n",
       "3   2013-07-01   4.10   10712200           0.0  16.370001     82.980003  0.10   \n",
       "4   2013-07-02   3.97   17766600           0.0  16.440001     83.540001  0.10   \n",
       "5   2013-07-03   4.06   11315900           0.0  16.200001     83.230003  0.10   \n",
       "6   2013-07-05   4.07    8965400           0.0  14.890000     84.419998  0.10   \n",
       "7   2013-07-08   4.00   16930900           0.0  14.780000     84.199997  0.10   \n",
       "8   2013-07-09   4.05    9550900           0.0  14.350000     84.580002  0.10   \n",
       "9   2013-07-10   3.98   19122800           0.0  14.210000     84.040001  0.09   \n",
       "10  2013-07-11   4.45  106975700           0.0  14.010000     82.750000  0.09   \n",
       "11  2013-07-12   4.32   50286600           0.0  13.840000     82.989998  0.09   \n",
       "12  2013-07-15   4.40   21953700           0.0  13.790000     83.040001  0.09   \n",
       "13  2013-07-16   4.43   39716700           0.0  14.420000     82.430000  0.09   \n",
       "14  2013-07-17   4.38   17002100           0.0  13.780000     82.709999  0.09   \n",
       "15  2013-07-18   4.64   70347000           0.0  13.770000     82.820000  0.09   \n",
       "16  2013-07-19   4.03  151516000           0.0  12.540000     82.580002  0.09   \n",
       "17  2013-07-22   3.90   50010900           0.0  12.290000     82.220001  0.09   \n",
       "18  2013-07-23   3.66   76847700           0.0  12.660000     82.010002  0.09   \n",
       "19  2013-07-24   3.63   50913500           0.0  13.180000     82.300003  0.09   \n",
       "\n",
       "    UMCSENT  UNRATE  time_idx chart  \n",
       "0      84.5     7.5         0   amd  \n",
       "1      84.5     7.5         1   amd  \n",
       "2      84.5     7.5         2   amd  \n",
       "3      85.1     7.3         3   amd  \n",
       "4      85.1     7.3         4   amd  \n",
       "5      85.1     7.3         5   amd  \n",
       "6      85.1     7.3         6   amd  \n",
       "7      85.1     7.3         7   amd  \n",
       "8      85.1     7.3         8   amd  \n",
       "9      85.1     7.3         9   amd  \n",
       "10     85.1     7.3        10   amd  \n",
       "11     85.1     7.3        11   amd  \n",
       "12     85.1     7.3        12   amd  \n",
       "13     85.1     7.3        13   amd  \n",
       "14     85.1     7.3        14   amd  \n",
       "15     85.1     7.3        15   amd  \n",
       "16     85.1     7.3        16   amd  \n",
       "17     85.1     7.3        17   amd  \n",
       "18     85.1     7.3        18   amd  \n",
       "19     85.1     7.3        19   amd  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GET SPY HISTORICAL\n",
    "TICKER = \"amd\"\n",
    "scraper = StockScraper(TICKER, interval=\"1d\", period=\"10y\")\n",
    "scraper.from_yahoo()\n",
    "sdata = scraper.data\n",
    "sdata[\"Date\"] = sdata.index.strftime(\"%Y-%m-%d\")\n",
    "sdata = sdata.reset_index(drop=True)[[\"Date\", \"Close\", \"Volume\", \"Stock Splits\"]]\n",
    "\n",
    "print(f\"SPY shape = {sdata.shape}\")\n",
    "\n",
    "# GET VIX HISTORICAL\n",
    "scraper = StockScraper(\"^VIX\", interval=\"1d\", period=\"10y\")\n",
    "scraper.from_yahoo()\n",
    "vix = scraper.data[[\"Close\"]].rename(columns={\"Close\": \"VIX\"})\n",
    "vix[\"Date\"] = vix.index.strftime(\"%Y-%m-%d\")\n",
    "vix = vix.reset_index(drop=True)\n",
    "\n",
    "print(f\"VIX shape = {vix.shape}\")\n",
    "\n",
    "# GET DOLLAR INDEX HISTORICAL\n",
    "scraper = StockScraper(\"DX-Y.NYB\", interval=\"1d\", period=\"15y\")\n",
    "scraper.from_yahoo()\n",
    "\n",
    "dix = scraper.data[[\"Close\"]].rename(columns={\"Close\": \"Dollar Index\"})\n",
    "dix[\"Date\"] = dix.index.strftime(\"%Y-%m-%d\")\n",
    "dix = dix.reset_index(drop=True)\n",
    "\n",
    "print(f\"DIX shape = {dix.shape}\")\n",
    "\n",
    "mdata = vix.merge(dix, on=\"Date\",how=\"left\" )\n",
    "sdata = sdata.merge(mdata, on=\"Date\", how=\"left\")\n",
    "print(f\"MERGE shape = {sdata.shape}\")\n",
    "\n",
    "\n",
    "# GET OPTIONS DATA\n",
    "if False:\n",
    "    options_cols = [\"Date\", \"Imp Vol\", \"Put/Call Vol\", \"Options Vol\", \"Put/Call OI\"]\n",
    "    options_data = pd.read_csv(f\"options_data/{TICKER}.csv\")\n",
    "    sdata = sdata.merge(options_data[options_cols], on=\"Date\",how=\"inner\" )\n",
    "    print(f\"Options shape = {options_data.shape}\")\n",
    "    print(f\"MERGE shape = {sdata.shape}\")\n",
    "    for col in [\"Imp Vol\"]:\n",
    "        sdata[col] = sdata[col].str.rstrip('%').astype('float') / 100.0\n",
    "\n",
    "\n",
    "stock_data = sdata.merge(macro_data, on=\"Date\", how=\"left\")\n",
    "stock_data[\"time_idx\"] = range(stock_data.shape[0])\n",
    "stock_data[\"chart\"] = TICKER\n",
    "\n",
    "stock_data[\"Dollar Index\"] = stock_data[\"Dollar Index\"].fillna(method=\"bfill\")\n",
    "\n",
    "print(f\"macro shape = {macro_data.shape}\")\n",
    "print(f\"MERGE shape = {sdata.shape}\")\n",
    "    \n",
    "stock_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd067d72-344c-44c6-a409-c98bff57737c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load Raw Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f82a0961-ec18-40da-a63b-4df646b321e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Stock Splits</th>\n",
       "      <th>VIX</th>\n",
       "      <th>Dollar Index</th>\n",
       "      <th>EFFR</th>\n",
       "      <th>UMCSENT</th>\n",
       "      <th>UNRATE</th>\n",
       "      <th>time_idx</th>\n",
       "      <th>chart</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Date, Close, Volume, Stock Splits, VIX, Dollar Index, EFFR, UMCSENT, UNRATE, time_idx, chart]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stock_data[stock_data[\"Dollar Index\"].isnull()]"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c7beea9-5865-43d0-8380-79a09eeb8bc6",
   "metadata": {},
   "source": [
    "# https://fred.stlouisfed.org/series/EFFR\n",
    "from os import path\n",
    "\n",
    "GLOBAL_TICKERS = [\"^VIX\", \"DX-Y.NYB\"], \n",
    "STOCK_TICKERS = [\"SPY\",\"^VIX\", \"DX-Y.NYB\"] # ,\"TSLA\",\"NVDA\",\"MSFT\", \"NFLX\"\n",
    "OPTIONS_NAME = [\"amd\",\"spy\",\"vix\"] # ,\"TSLA\",\"NVDA\",\"MSFT\", \"NFLX\"\n",
    "\n",
    "stock_arr = []\n",
    "for idx, stock in enumerate(STOCK_TICKERS): \n",
    "    scraper = StockScraper(stock, interval=\"1d\", period=\"10y\")\n",
    "    scraper.from_yahoo()\n",
    "\n",
    "    data = scraper.data\n",
    "    # if interval == 1d\n",
    "    data[\"Date\"] = data.index.strftime(\"%Y-%m-%d\")\n",
    "    data = data.reset_index(drop=True)\n",
    "    \n",
    "    data = data.merge(macro_data, on=\"Date\", how=\"inner\")\n",
    "    \n",
    "    fn = f\"options_data/{OPTIONS_NAME[idx]}.csv\"\n",
    "    if path.exists(fn):\n",
    "        options_data = pd.read_csv(fn)\n",
    "        data = data.merge(options_data, on=\"Date\",how=\"inner\" )\n",
    "\n",
    "    data[\"chart\"] = stock\n",
    "    data[\"time_idx\"] = range(len(data))\n",
    "    stock_arr.append(data)\n",
    "\n",
    "stock_data = pd.concat(stock_arr).reset_index(drop=True)\n",
    "\n",
    "for col in [\"Imp Vol\", \"1D IV Chg\", \"IV Rank\", \"IV Pctl\"]:\n",
    "    stock_data[col] = stock_data[col].str.rstrip('%').astype('float') / 100.0\n",
    "    \n",
    "stock_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b264bea-bdf6-4101-a9c8-d08b169cec07",
   "metadata": {},
   "source": [
    "### More Data\n",
    "\n",
    "with more information the assumption is the model will get better at predictions.\n",
    "1. fed meetings\n",
    "2. holidays\n",
    "3. stock splits\n",
    "4. options volume\n",
    "5. options put/call agg volume\n",
    "\n",
    "It might also be interesting to train several stocks / indexes into one model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed74275-bb3c-42de-99f9-a1b8cb1a7116",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create Model Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9edb47e-8aae-494d-8f8b-46a5dc4c6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch-forecasting.readthedocs.io/en/latest/tutorials/building.html#passing-data\n",
    "\n",
    "max_prediction_length = 6  # forecast 6 months\n",
    "max_encoder_length = 30  # use 24 months of history\n",
    "max_epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# since the datetime is not periodic, we're adding a \n",
    "# fixed size incrementation for each data cell\n",
    "data = stock_data\n",
    "\n",
    "training_cutoff = data[\"time_idx\"].max() - max_prediction_length\n",
    "\n",
    "torch_device = \"cpu\"\n",
    "tdevice = torch.device(torch_device)\n",
    "    \n",
    "# create trainer; normalize data, set weights, create tensors, validation - the whole 9\n",
    "training = TimeSeriesDataSet(\n",
    "    data[lambda x: x.time_idx <= training_cutoff],\n",
    "    time_idx=\"time_idx\",\n",
    "    target=\"Close\",  # [\"Close\"],\n",
    "    \n",
    "    group_ids=[\"chart\"],\n",
    "    weight=None,\n",
    "    \n",
    "    max_encoder_length=max_encoder_length,\n",
    "    min_encoder_length=max_encoder_length,  # allow predictions without history\n",
    "    min_prediction_length=1,\n",
    "    max_prediction_length=max_prediction_length,\n",
    "    \n",
    "    static_reals=[],\n",
    "    time_varying_known_categoricals=[],\n",
    "\n",
    "    time_varying_unknown_reals=[\n",
    "        # \"Imp Vol\", \"Put/Call Vol\", \"Options Vol\", \"Put/Call OI\", \n",
    "        \"EFFR\", \"UMCSENT\", \"UNRATE\", \"Dollar Index\", \"VIX\",  \"Close\", \"Volume\"\n",
    "    ],\n",
    "    time_varying_known_reals=[\"time_idx\"],\n",
    "    time_varying_unknown_categoricals=[],\n",
    "    \n",
    "    variable_groups={},\n",
    "    lags={},\n",
    "    static_categoricals=[\"chart\"],\n",
    "    \n",
    "    constant_fill_strategy={},\n",
    "    \n",
    "    # TorchNormalizer, GroupNormalizer, NaNLabelEncoder, EncoderNormalizer\n",
    "    # MultiNormalizer\n",
    "    target_normalizer=GroupNormalizer(\n",
    "       groups=[\"chart\"], transformation=\"softplus\"\n",
    "    ), \n",
    "\n",
    "\n",
    "    add_relative_time_idx=True,  # add as feature\n",
    "    add_target_scales=True,  # add as feature\n",
    "    add_encoder_length=True,  # add as feature\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e840f0da-6285-497e-97ee-9ab183c731c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f8c3182-9fdb-40f0-b426-1d8b88f9ad0e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create validation set (predict=True) which means to predict the\n",
    "# last max_prediction_length points in time for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    "    training, data, predict=True, stop_randomization=True\n",
    ")\n",
    "# create dataloaders for model\n",
    "batch_size = batch_size\n",
    "train_dataloader = training.to_dataloader(\n",
    "    train=True, batch_size=batch_size, num_workers=0\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    "    train=False, batch_size=batch_size * 10, num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22757519-793a-4e2b-a7a3-4aa6f0beb130",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10.8617, device='mps:0')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  # avoid printing out absolute paths\n",
    "\n",
    "# calculate baseline mean absolute error, i.e. predict next value as the last available value from the history\n",
    "baseline_predictions = Baseline().predict(val_dataloader, return_y=True)\n",
    "MAE()(baseline_predictions.output, baseline_predictions.y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4eac552-d0a3-4b39-a9bc-415aa03a771a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Tuning the model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a70e9591-0695-4369-bfd8-de3715b5070c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 42\n",
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters in network: 80.0k\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "630fc4671b034e7582b20db152dff800",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.03548133892335756\n",
      "Restoring states from the checkpoint path at /Users/dbell/Documents/mycode/stockai/.lr_find_84f7d903-5998-45df-8e64-ea6d0966ba00.ckpt\n",
      "Restored all states from the checkpoint at /Users/dbell/Documents/mycode/stockai/.lr_find_84f7d903-5998-45df-8e64-ea6d0966ba00.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suggested learning rate: 0.03548133892335756\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# configure network and trainer\n",
    "pl.seed_everything(42)\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=torch_device,\n",
    "    # clipping gradients is a hyperparameter and important to prevent divergance\n",
    "    # of the gradient for recurrent neural networks\n",
    "    gradient_clip_val=0.6943055468697653,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "    'gradient_clip_val': 0.016723475628684332, \n",
    "    'hidden_size': 12, \n",
    "    'dropout': 0.20273552774959722, \n",
    "    'hidden_continuous_size': 9, \n",
    "    'attention_head_size': 4, \n",
    "    'learning_rate': 0.010477429830518623\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Trial 0 finished with value: 56.48472213745117 and parameters: \n",
    "{\n",
    "    'gradient_clip_val': 0.6943055468697653, \n",
    "    'hidden_size': 35, \n",
    "    'dropout': 0.24100408480680044, \n",
    "    'hidden_continuous_size': 9, \n",
    "    'attention_head_size': 3, \n",
    "    'learning_rate': 0.003134745802918898\n",
    "}. Best is trial 0 with value: 56.48472213745117.\n",
    "\"\"\"\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    # not meaningful for finding the learning rate but otherwise very important\n",
    "    learning_rate=0.003134745802918898,\n",
    "    hidden_size=35,  # most important hyperparameter apart from learning rate\n",
    "    # number of attention heads. Set to up to 4 for large datasets\n",
    "    attention_head_size=3,\n",
    "    dropout=0.24100408480680044,  # between 0.1 and 0.3 are good values\n",
    "    hidden_continuous_size=9,  # set to <= hidden_size\n",
    "    loss=QuantileLoss(),\n",
    "    optimizer=\"Ranger\"\n",
    "    # reduce learning rate if no improvement in validation loss after x epochs\n",
    "    # reduce_on_plateau_patience=1000,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")\n",
    "\n",
    "# find optimal learning rate\n",
    "from lightning.pytorch.tuner import Tuner\n",
    "\n",
    "res = Tuner(trainer).lr_find(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    "    max_lr=10.0,\n",
    "    min_lr=1e-6,\n",
    ")\n",
    "\n",
    "print(f\"suggested learning rate: {res.suggestion()}\")\n",
    "fig = res.plot(show=True, suggest=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f953dc33-cecb-43ab-9076-0d97b7b9fc85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-06-28 17:18:19,480] A new study created in memory with name: no-name-4efa81e3-1155-4fb8-832b-e133e3d41858\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-06-28 17:27:49,904] Trial 0 finished with value: 5.527894973754883 and parameters: {'gradient_clip_val': 0.07957531048227721, 'hidden_size': 73, 'dropout': 0.12144553040744104, 'hidden_continuous_size': 28, 'attention_head_size': 1, 'learning_rate': 0.003993726374541425}. Best is trial 0 with value: 5.527894973754883.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n",
      "[I 2023-06-28 17:37:55,086] Trial 1 finished with value: 10.788082122802734 and parameters: {'gradient_clip_val': 0.058791553562941, 'hidden_size': 101, 'dropout': 0.1260704851769212, 'hidden_continuous_size': 43, 'attention_head_size': 1, 'learning_rate': 0.0011859244679654297}. Best is trial 0 with value: 5.527894973754883.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[W 2023-06-28 17:40:00,895] Trial 2 failed with parameters: {'gradient_clip_val': 0.01465191192791452, 'hidden_size': 84, 'dropout': 0.19826777926388603, 'hidden_continuous_size': 45, 'attention_head_size': 1, 'learning_rate': 0.0023515302783046425} because of the following error: RuntimeError('element 0 of tensors does not require grad and does not have a grad_fn').\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py\", line 199, in objective\n",
      "    trainer.fit(model, train_dataloaders=train_dataloaders, val_dataloaders=val_dataloaders)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 531, in fit\n",
      "    call._call_and_handle_interrupt(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 42, in _call_and_handle_interrupt\n",
      "    return trainer_fn(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 570, in _fit_impl\n",
      "    self._run(model, ckpt_path=ckpt_path)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 975, in _run\n",
      "    results = self._run_stage()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py\", line 1018, in _run_stage\n",
      "    self.fit_loop.run()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 201, in run\n",
      "    self.advance()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py\", line 354, in advance\n",
      "    self.epoch_loop.run(self._data_fetcher)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 133, in run\n",
      "    self.advance(data_fetcher)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py\", line 218, in advance\n",
      "    batch_output = self.automatic_optimization.run(trainer.optimizers[0], kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 185, in run\n",
      "    self._optimizer_step(kwargs.get(\"batch_idx\", 0), closure)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 260, in _optimizer_step\n",
      "    call._call_lightning_module_hook(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 140, in _call_lightning_module_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/module.py\", line 1256, in optimizer_step\n",
      "    optimizer.step(closure=optimizer_closure)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/optimizer.py\", line 155, in step\n",
      "    step_output = self._strategy.optimizer_step(self._optimizer, closure, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 225, in optimizer_step\n",
      "    return self.precision_plugin.optimizer_step(optimizer, model=model, closure=closure, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 114, in optimizer_step\n",
      "    return optimizer.step(closure=closure, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/optim/optimizer.py\", line 280, in wrapper\n",
      "    out = func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/utils/_contextlib.py\", line 115, in decorate_context\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pytorch_optimizer/optimizer/ranger.py\", line 100, in step\n",
      "    loss = closure()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 101, in _wrap_closure\n",
      "    closure_result = closure()\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 140, in __call__\n",
      "    self._result = self.closure(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 135, in closure\n",
      "    self._backward_fn(step_output.closure_loss)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py\", line 232, in backward_fn\n",
      "    call._call_strategy_hook(self.trainer, \"backward\", loss, optimizer)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py\", line 287, in _call_strategy_hook\n",
      "    output = fn(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py\", line 200, in backward\n",
      "    self.precision_plugin.backward(closure_loss, self.lightning_module, optimizer, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py\", line 67, in backward\n",
      "    model.backward(tensor, *args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/module.py\", line 1046, in backward\n",
      "    loss.backward(*args, **kwargs)\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/_tensor.py\", line 487, in backward\n",
      "    torch.autograd.backward(\n",
      "  File \"/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/autograd/__init__.py\", line 200, in backward\n",
      "    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n",
      "RuntimeError: element 0 of tensors does not require grad and does not have a grad_fn\n",
      "[W 2023-06-28 17:40:00,909] Trial 2 failed with value None.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpytorch_forecasting\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtemporal_fusion_transformer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuning\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m optimize_hyperparameters\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# create study\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m study \u001b[38;5;241m=\u001b[39m \u001b[43moptimize_hyperparameters\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptuna_test\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_clip_val_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_continuous_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m128\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_head_size_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdropout_range\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlimit_train_batches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreduce_on_plateau_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_learning_rate_finder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# use Optuna to find ideal learning rate or use in-built learning rate finder\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# save study results - also we can resume tuning at a later point in time\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_study.pkl\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fout:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:207\u001b[0m, in \u001b[0;36moptimize_hyperparameters\u001b[0;34m(train_dataloaders, val_dataloaders, model_path, max_epochs, n_trials, timeout, gradient_clip_val_range, hidden_size_range, hidden_continuous_size_range, attention_head_size_range, dropout_range, learning_rate_range, use_learning_rate_finder, trainer_kwargs, log_dir, study, verbose, pruner, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m study \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m\"\u001b[39m, pruner\u001b[38;5;241m=\u001b[39mpruner)\n\u001b[0;32m--> 207\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m study\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/study.py:443\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    341\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    348\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    349\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    350\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \n\u001b[1;32m    352\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    446\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    449\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    450\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    451\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/_optimize.py:66\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 66\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/_optimize.py:163\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 163\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/_optimize.py:251\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    247\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    250\u001b[0m ):\n\u001b[0;32m--> 251\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/optuna/study/_optimize.py:200\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    203\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pytorch_forecasting/models/temporal_fusion_transformer/tuning.py:199\u001b[0m, in \u001b[0;36moptimize_hyperparameters.<locals>.objective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m    196\u001b[0m     model\u001b[38;5;241m.\u001b[39mhparams\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39msuggest_loguniform(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlearning_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39mlearning_rate_range)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# fit\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m \u001b[38;5;66;03m# report result\u001b[39;00m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:531\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    529\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    530\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 531\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:42\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     45\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:570\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    561\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    562\u001b[0m )\n\u001b[1;32m    564\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    566\u001b[0m     ckpt_path,\n\u001b[1;32m    567\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    568\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    569\u001b[0m )\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    573\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:975\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    972\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    973\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 975\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    980\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1018\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1016\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m   1017\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1018\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:133\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 133\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    135\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:218\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    217\u001b[0m         \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m         batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmanual_optimization\u001b[38;5;241m.\u001b[39mrun(kwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:185\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m         closure()\n\u001b[1;32m    180\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 185\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_idx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    187\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mloss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:260\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_ready()\n\u001b[1;32m    259\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 260\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    263\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    264\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    266\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptim_progress\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mstep\u001b[38;5;241m.\u001b[39mincrement_completed()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:140\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 140\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    143\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/module.py:1256\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimizer_step\u001b[39m(\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1220\u001b[0m     epoch: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1223\u001b[0m     optimizer_closure: Optional[Callable[[], Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1224\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1225\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer`\u001b[39;00m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;124;03m    calls the optimizer.\u001b[39;00m\n\u001b[1;32m   1227\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1254\u001b[0m \u001b[38;5;124;03m                    pg[\"lr\"] = lr_scale * self.learning_rate\u001b[39;00m\n\u001b[1;32m   1255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/optimizer.py:155\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWhen `optimizer.step(closure)` is called, the closure should be callable\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 155\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:225\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# TODO(fabric): remove assertion once strategy's optimizer_step typing is fixed\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 225\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:114\u001b[0m, in \u001b[0;36mPrecisionPlugin.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Hook to run the optimizer step.\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 114\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/optim/optimizer.py:280\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    277\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs),\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    278\u001b[0m                                \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbut got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 280\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    283\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/pytorch_optimizer/optimizer/ranger.py:100\u001b[0m, in \u001b[0;36mRanger.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m closure \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     99\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 100\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m group:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:101\u001b[0m, in \u001b[0;36mPrecisionPlugin._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_wrap_closure\u001b[39m(\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     91\u001b[0m     model: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpl.LightningModule\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     optimizer: Optimizer,\n\u001b[1;32m     93\u001b[0m     closure: Callable[[], Any],\n\u001b[1;32m     94\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     95\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    ``on_before_optimizer_step`` hook is called.\u001b[39;00m\n\u001b[1;32m     97\u001b[0m \n\u001b[1;32m     98\u001b[0m \u001b[38;5;124;03m    The closure (generally) runs ``backward`` so this allows inspecting gradients in this hook. This structure is\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    consistent with the ``PrecisionPlugin`` subclasses that cannot pass ``optimizer.step(closure)`` directly.\u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m closure_result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:140\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:135\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_zero_grad_fn()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backward_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep_output\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure_loss\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m step_output\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:232\u001b[0m, in \u001b[0;36m_AutomaticOptimization._make_backward_fn.<locals>.backward_fn\u001b[0;34m(loss)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward_fn\u001b[39m(loss: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 232\u001b[0m     \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:287\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    290\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:200\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    198\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpre_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[0;32m--> 200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m closure_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision_plugin\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision_plugin.py:67\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[0;34m(self, tensor, model, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     51\u001b[0m     tensor: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m     56\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     57\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \n\u001b[1;32m     59\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/lightning/pytorch/core/module.py:1046\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fabric\u001b[38;5;241m.\u001b[39mbackward(loss, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1046\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/stockai/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# export PYTORCH_ENABLE_MPS_FALLBACK=1\n",
    "\n",
    "import pickle\n",
    "\n",
    "from pytorch_forecasting.models.temporal_fusion_transformer.tuning import optimize_hyperparameters\n",
    "# create study\n",
    "study = optimize_hyperparameters(\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    model_path=\"optuna_test\",\n",
    "    n_trials=100,\n",
    "    max_epochs=max_epochs,\n",
    "    gradient_clip_val_range=(0.01, 1.0),\n",
    "    hidden_size_range=(8, 128),\n",
    "    hidden_continuous_size_range=(8, 128),\n",
    "    attention_head_size_range=(1, 4),\n",
    "    learning_rate_range=(0.001, 0.1),\n",
    "    dropout_range=(0.1, 0.3),\n",
    "    trainer_kwargs=dict(limit_train_batches=30),\n",
    "    reduce_on_plateau_patience=4,\n",
    "    use_learning_rate_finder=False,  # use Optuna to find ideal learning rate or use in-built learning rate finder\n",
    ")\n",
    "\n",
    "# save study results - also we can resume tuning at a later point in time\n",
    "with open(\"test_study.pkl\", \"wb\") as fout:\n",
    "    pickle.dump(study, fout)\n",
    "\n",
    "# show best hyperparameters\n",
    "print(study.best_trial.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec84d5f-cb89-476a-8fa9-399a0b9bfd01",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8a5db6b9-12b3-41c5-bfb4-d2e6fc8e0ad6",
   "metadata": {},
   "source": [
    "# import tensorflow as tf\n",
    "# import tensorboard as tb\n",
    "# tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e5c15e-ef51-4952-b47f-0b5bd7f689bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# configure network and trainer\n",
    "early_stop_callback = EarlyStopping(monitor=\"val_loss\", min_delta=1e-6, patience=10, verbose=False, mode=\"min\")\n",
    "lr_logger = LearningRateMonitor()  # log the learning rate\n",
    "logger = TensorBoardLogger(\"lightning_logs\")  # logging results to a tensorboard\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=max_epochs,\n",
    "    accelerator=torch_device,\n",
    "    enable_model_summary=True,\n",
    "    gradient_clip_val=0.23671769794503256,\n",
    "    # limit_train_batches=50,  # coment in for training, running validation every 30 batches\n",
    "    # fast_dev_run=True,  # comment in to check that networkor dataset has no serious bugs\n",
    "    callbacks=[lr_logger, early_stop_callback],\n",
    "    logger=logger,\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "Trial 1 finished with value: 2.512352466583252 and parameters: \n",
    "{\n",
    "    'gradient_clip_val': 0.23671769794503256, \n",
    "    'hidden_size': 14, \n",
    "    'dropout': 0.17934389477113102, \n",
    "    'hidden_continuous_size': 12, \n",
    "    'attention_head_size': 2, \n",
    "    'learning_rate': 0.0016975585990462374\n",
    "}. Best is trial 1 with value: 2.512352466583252.\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "Trial 0 finished with value: 3.0804049968719482 and parameters: {\n",
    "    'gradient_clip_val': 0.018173198922575805, \n",
    "    'hidden_size': 19, \n",
    "    'dropout': 0.1691311061383082, \n",
    "    'hidden_continuous_size': 11, \n",
    "    'attention_head_size': 2, \n",
    "    'learning_rate': 0.001059429134884675\n",
    "}. Best is trial 0 with value: 3.0804049968719482.\n",
    "\"\"\"\n",
    "\n",
    "tft = TemporalFusionTransformer.from_dataset(\n",
    "    training,\n",
    "    learning_rate=0.001059429134884675,\n",
    "    hidden_size=40,\n",
    "    attention_head_size=2,\n",
    "    dropout=0.1691311061383082,\n",
    "    hidden_continuous_size=12,\n",
    "    loss=QuantileLoss(),\n",
    "    log_interval=10,  # uncomment for learning rate finder and otherwise, e.g. to 10 for logging every 10 batches\n",
    "    optimizer=\"Ranger\",\n",
    "    reduce_on_plateau_patience=4,\n",
    ")\n",
    "print(f\"Number of parameters in network: {tft.size()/1e3:.1f}k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aeaabc8-443e-4a76-ad68-0c5686abc656",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fit network\n",
    "trainer.fit(\n",
    "    tft,\n",
    "    train_dataloaders=train_dataloader,\n",
    "    val_dataloaders=val_dataloader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280592f-06c0-49e1-b753-e6552bb7fa2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load the best model according to the validation loss\n",
    "# (given that we use early stopping, this is not necessarily the last epoch)\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "best_tft = TemporalFusionTransformer.load_from_checkpoint(best_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c31e90-74d5-4760-9a3f-0482092b82f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model_path"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5b03f0a4-da47-4d12-ae1d-4854b9230552",
   "metadata": {
    "tags": []
   },
   "source": [
    "# calcualte mean absolute error on validation set\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True, trainer_kwargs=dict(accelerator=\"cpu\"))\n",
    "MAE()(predictions.output, predictions.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c4ca6-3a21-475e-afae-061cbe186c93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# raw predictions are a dictionary from which all kind of information including quantiles can be extracted\n",
    "raw_predictions = best_tft.predict(val_dataloader, mode=\"raw\", return_x=True, fast_dev_run=False)\n",
    "STOCK_TICKERS = [\"spy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54ee1c2-8857-4aba-8acf-333df12f0fe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for idx in range(len(STOCK_TICKERS)):  # plot 10 examples\n",
    "    plt = best_tft.plot_prediction(raw_predictions.x, raw_predictions.output, idx=idx, add_loss_to_title=True)\n",
    "    plt.legend(\"hello\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e101c51-115d-4cca-9e35-41c1c6fc8b45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# calcualte metric by which to display\n",
    "predictions = best_tft.predict(val_dataloader, return_y=True)\n",
    "mean_losses = SMAPE(reduction=\"none\")(predictions.output, predictions.y).mean(1)\n",
    "indices = mean_losses.argsort(descending=True)  # sort losses\n",
    "for idx in range(indices.shape[0]):  # plot 10 examples\n",
    "    best_tft.plot_prediction(\n",
    "        raw_predictions.x,\n",
    "        raw_predictions.output,\n",
    "        idx=indices[idx],\n",
    "        add_loss_to_title=SMAPE(quantiles=best_tft.loss.quantiles),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b54923-b3b8-4913-91bd-5898bd6bce0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictions = best_tft.predict(val_dataloader, return_x=True)\n",
    "predictions_vs_actuals = best_tft.calculate_prediction_actual_by_variable(predictions.x, predictions.output)\n",
    "best_tft.plot_prediction_actual_by_variable(predictions_vs_actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848c5842-ca3e-487a-a34a-e63844198a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interpretation = best_tft.interpret_output(raw_predictions.output, reduction=\"sum\")\n",
    "best_tft.plot_interpretation(interpretation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f086ee-53d5-4fb5-93b8-04af2be5297a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0264c552-2ce7-4c9a-aee6-b12de7c3ff58",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
